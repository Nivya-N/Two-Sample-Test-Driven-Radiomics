{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13rmDZEaCdXlVFeY52r1ZX-PrSBZURrwD",
      "authorship_tag": "ABX9TyN6QaZjf6HXx5P4YWs2xOTo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vI3f9FyOJ9gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j73XszMqJ5PM",
        "outputId": "6cdf30df-0a7e-4dfa-f39b-2c451c4d6a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Significant Features:\n",
            "                                 Feature  U-Statistic       P-Value  \\\n",
            "0                           10Percentile       7650.0  3.368980e-32   \n",
            "1                           90Percentile       7648.0  9.279862e-32   \n",
            "2                                 Energy       5670.0  4.361295e-08   \n",
            "3                                Entropy       7650.0  7.136304e-30   \n",
            "4                     InterquartileRange       7650.0  3.303890e-32   \n",
            "..                                   ...          ...           ...   \n",
            "81  SmallDependenceHighGrayLevelEmphasis       7600.0  3.856376e-29   \n",
            "82   SmallDependenceLowGrayLevelEmphasis       7560.0  1.463789e-28   \n",
            "83                              Busyness       1492.0  4.383381e-12   \n",
            "85                            Complexity       7645.0  8.455530e-30   \n",
            "86                              Strength       2512.0  9.768401e-05   \n",
            "\n",
            "    Significant  \n",
            "0          True  \n",
            "1          True  \n",
            "2          True  \n",
            "3          True  \n",
            "4          True  \n",
            "..          ...  \n",
            "81         True  \n",
            "82         True  \n",
            "83         True  \n",
            "85         True  \n",
            "86         True  \n",
            "\n",
            "[82 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import mannwhitneyu\n",
        "import numpy as np\n",
        "\n",
        "# Load the two datasets (MCI and NC) from CSV files\n",
        "file_mci = \"/content/drive/MyDrive/radiomic_features_bratshgg_dec22.csv\"  # Replace with your actual file path\n",
        "file_nc = \"/content/drive/MyDrive/radiomic_features_bratslgg_dec22.csv\"    # Replace with your actual file path\n",
        "\n",
        "data_mci = pd.read_csv(file_mci)\n",
        "data_nc = pd.read_csv(file_nc)\n",
        "\n",
        "# Ensure that the data contains only numerical features\n",
        "# If the first column is an identifier, drop it\n",
        "if data_mci.columns[0].lower() in [\"id\", \"subject_id\"]:\n",
        "    data_mci = data_mci.drop(columns=data_mci.columns[0])\n",
        "    data_nc = data_nc.drop(columns=data_nc.columns[0])\n",
        "\n",
        "def extract_number(array_string):\n",
        "    if isinstance(array_string, str) and 'array' in array_string:\n",
        "        return float(array_string.split('(')[1].split(')')[0])\n",
        "    else:\n",
        "        return array_string\n",
        "\n",
        "# Apply the function to each column\n",
        "for column in data_mci .columns:\n",
        "    data_mci [column] = data_mci [column].apply(extract_number)\n",
        "\n",
        "for column in data_nc .columns:\n",
        "    data_nc [column] = data_nc [column].apply(extract_number)\n",
        "# Perform Mann-Whitney U test for each feature\n",
        "results = []\n",
        "for feature in data_mci.columns:\n",
        "    # Extract feature values for MCI and NC groups\n",
        "    mci_values = data_mci[feature].values\n",
        "    nc_values = data_nc[feature].values\n",
        "\n",
        "    # Perform the Mann-Whitney U test\n",
        "    stat, p_value = mannwhitneyu(mci_values, nc_values, alternative='two-sided')\n",
        "\n",
        "    # Append results\n",
        "    results.append((feature, stat, p_value))\n",
        "\n",
        "# Convert results to a DataFrame for easy analysis\n",
        "results_df = pd.DataFrame(results, columns=[\"Feature\", \"U-Statistic\", \"P-Value\"])\n",
        "\n",
        "# Apply a significance threshold (e.g., 0.05) and adjust for multiple comparisons if needed\n",
        "significance_threshold = 0.05\n",
        "results_df[\"Significant\"] = results_df[\"P-Value\"] < significance_threshold\n",
        "\n",
        "# Save results to a CSV file\n",
        "results_df.to_csv(\"mann_whitney_results.csv\", index=False)\n",
        "\n",
        "# Display significant features\n",
        "significant_features = results_df[results_df[\"Significant\"]]\n",
        "print(f\"Significant Features:\\n{significant_features}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Type I Error: Simulate the null hypothesis\n",
        "def calculate_type_I_error(data, num_simulations=425, significance_threshold=0.05):\n",
        "    all_features = pd.concat([data_mci, data_nc])\n",
        "    type_I_count = 0\n",
        "\n",
        "    for _ in range(num_simulations):\n",
        "        # Randomly split data into two groups\n",
        "        group1 = all_features.sample(frac=0.5, random_state=_)\n",
        "        group2 = all_features.drop(group1.index)\n",
        "\n",
        "        # Perform Mann-Whitney U test for each feature\n",
        "        for feature in group1.columns:\n",
        "            stat, p_value = mannwhitneyu(group1[feature], group2[feature], alternative='two-sided')\n",
        "            if p_value < significance_threshold:\n",
        "                type_I_count += 1\n",
        "\n",
        "    type_I_error_rate = type_I_count / (num_simulations * len(data_mci.columns))\n",
        "    return type_I_error_rate\n"
      ],
      "metadata": {
        "id": "E50FbEJv7gd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Type II Error: Simulate the alternative hypothesis\n",
        "def calculate_type_II_error(data_mci, data_nc, num_simulations=1000, significance_threshold=0.05, effect_size=0.5):\n",
        "    type_II_count = 0\n",
        "\n",
        "    for _ in range(num_simulations):\n",
        "        # Introduce an artificial shift (effect size) to simulate the alternative hypothesis\n",
        "        shifted_mci = data_mci + np.random.normal(effect_size, 0.1, size=data_mci.shape)\n",
        "        shifted_nc = data_nc.copy()\n",
        "\n",
        "        # Perform Mann-Whitney U test for each feature\n",
        "        for feature in data_mci.columns:\n",
        "            stat, p_value = mannwhitneyu(shifted_mci[feature], shifted_nc[feature], alternative='two-sided')\n",
        "            if p_value >= significance_threshold:\n",
        "                type_II_count += 1\n",
        "                type_II_error_rate = type_II_count / (num_simulations * len(data_mci.columns))\n",
        "    return type_II_error_rate"
      ],
      "metadata": {
        "id": "H0ZbMFImNFSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate errors\n",
        "type_I_error = calculate_type_I_error(data_mci)\n",
        "type_II_error = calculate_type_II_error(data_mci, data_nc)\n",
        "\n",
        "print(f\"Type I Error Rate: {type_I_error}\")\n",
        "print(f\"Type II Error Rate: {type_II_error}\")\n",
        "print(f\"Power of the Test: {1 - type_II_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzgH1zdKNM8r",
        "outputId": "4151eec1-6017-479e-a8a8-bcd362d63c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type I Error Rate: 0.026450304259634887\n",
            "Type II Error Rate: 0.011494252873563218\n",
            "Power of the Test: 0.9885057471264368\n"
          ]
        }
      ]
    }
  ]
}